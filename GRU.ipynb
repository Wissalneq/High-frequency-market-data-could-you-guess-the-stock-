{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "461e3879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import GRU, Dense, Input, Bidirectional\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "X_train =pd.read_csv('C:\\\\Users\\\\Dell\\\\Desktop\\\\op\\\\data\\\\X_train.csv')\n",
    "Y_train =pd.read_csv(\"C:\\\\Users\\\\Dell\\\\Desktop\\\\op\\\\data\\\\Y_train.csv\")\n",
    "\n",
    "X_test =pd.read_csv(\"C:\\\\Users\\\\Dell\\\\Desktop\\\\op\\\\data\\\\X_test.csv\")\n",
    "Y_test =pd.read_csv(\"C:\\\\Users\\\\Dell\\\\Desktop\\\\op\\\\data\\\\Y_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5af955d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding de 'venue', 'action', et 'trade'\n",
    "def one_hot_encode(df, column, num_categories):\n",
    "    return pd.get_dummies(df[column], prefix=column).reindex(columns=[f\"{column}_{i}\" for i in range(num_categories)], fill_value=0)\n",
    "\n",
    "df1 = one_hot_encode(X_train, 'venue', 8)\n",
    "df2 = one_hot_encode(X_train, 'action', 8)\n",
    "df3 = one_hot_encode(X_train, 'trade', 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f23aa712",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Log Transform\n",
    "X_train['flux'] = X_train['flux'] - X_train['flux'].min() + 1\n",
    "data = {\n",
    "    'log(bid_size+1)': np.log(X_train['bid_size'] + 1),\n",
    "    'log(ask_size+1)': np.log(X_train['ask_size'] + 1),\n",
    "    'log(flux)': np.log(X_train['flux'])\n",
    "}\n",
    "dfa = pd.DataFrame(data)\n",
    "X_selected = X_train[['bid', 'ask', 'price']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdd2b0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combiner les features\n",
    "df_combined = pd.concat([df1, df2, df3, X_selected, dfa], axis=1)\n",
    "\n",
    "# Reshape the data to create sequences of (100, 30)\n",
    "# We need to ensure we have enough rows to create full sequences\n",
    "num_sequences = len(df_combined) // 100\n",
    "X_reshaped = df_combined.iloc[:num_sequences * 100].values.reshape(num_sequences, 100, 30)\n",
    "\n",
    "# Convertir les labels en tenseurs\n",
    "Y_labels = pd.get_dummies(Y_train['eqt_code_cat']).values\n",
    "Y_reshaped = Y_labels[:num_sequences]\n",
    "\n",
    "# Conversion en tenseurs\n",
    "X_tensor = tf.convert_to_tensor(X_reshaped, dtype=tf.float32)\n",
    "Y_tensor = tf.convert_to_tensor(Y_reshaped, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "414955d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Définir la taille d'une observation\n",
    "sequence_length = 100\n",
    "feature_dim = 30\n",
    "\n",
    "# Définir l'entrée du modèle\n",
    "input_layer = Input(shape=(sequence_length, feature_dim))\n",
    "\n",
    "# Ajouter des couches GRU bidirectionnelles\n",
    "gru_1 = Bidirectional(GRU(64, return_sequences=True))(input_layer)\n",
    "gru_2 = Bidirectional(GRU(64))(gru_1)\n",
    "\n",
    "# Ajouter des couches Denses\n",
    "dense_1 = Dense(64, activation='selu')(gru_2)\n",
    "output_layer = Dense(24, activation='softmax')(dense_1)\n",
    "\n",
    "# Créer le modèle\n",
    "model = Model(inputs=input_layer, outputs=output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2002e4f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 100, 30)]         0         \n",
      "                                                                 \n",
      " bidirectional (Bidirection  (None, 100, 128)          36864     \n",
      " al)                                                             \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirecti  (None, 128)               74496     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 24)                1560      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121176 (473.34 KB)\n",
      "Trainable params: 121176 (473.34 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Compiler le modèle\n",
    "optimizer = Adam(learning_rate=3e-3)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "# Afficher un résumé du modèle\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ec7facd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "WARNING:tensorflow:From C:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "113/113 [==============================] - 325s 2s/step - loss: nan - accuracy: 0.0683\n",
      "Epoch 2/3\n",
      "113/113 [==============================] - 162s 1s/step - loss: nan - accuracy: 0.0417\n",
      "Epoch 3/3\n",
      "113/113 [==============================] - 163s 1s/step - loss: nan - accuracy: 0.0417\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2a79e5b9e90>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entraîner le modèle\n",
    "model.fit(X_tensor, Y_tensor, batch_size=1000, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "983b30d2",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 662. MiB for an array with shape (18, 4824000) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 27\u001b[0m\n\u001b[0;32m     24\u001b[0m X_combined_test \u001b[38;5;241m=\u001b[39m df_combined_test\u001b[38;5;241m.\u001b[39miloc[:num_sequences_test \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m]\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Reshape the data to the required shape\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m X_reshaped_test \u001b[38;5;241m=\u001b[39m X_combined_test\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mreshape(num_sequences_test, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m30\u001b[39m)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Convertir les labels en tenseurs pour Y_test\u001b[39;00m\n\u001b[0;32m     30\u001b[0m Y_labels_test \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mget_dummies(Y_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meqt_code_cat\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mvalues\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:11738\u001b[0m, in \u001b[0;36mDataFrame.values\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m  11664\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m  11665\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalues\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[0;32m  11666\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m  11667\u001b[0m \u001b[38;5;124;03m    Return a Numpy representation of the DataFrame.\u001b[39;00m\n\u001b[0;32m  11668\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  11736\u001b[0m \u001b[38;5;124;03m           ['monkey', nan, None]], dtype=object)\u001b[39;00m\n\u001b[0;32m  11737\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m> 11738\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_consolidate_inplace()\n\u001b[0;32m  11739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mas_array()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:5980\u001b[0m, in \u001b[0;36mNDFrame._consolidate_inplace\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   5977\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mf\u001b[39m():\n\u001b[0;32m   5978\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mconsolidate()\n\u001b[1;32m-> 5980\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_protect_consolidate(f)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:5968\u001b[0m, in \u001b[0;36mNDFrame._protect_consolidate\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m   5966\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f()\n\u001b[0;32m   5967\u001b[0m blocks_before \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mblocks)\n\u001b[1;32m-> 5968\u001b[0m result \u001b[38;5;241m=\u001b[39m f()\n\u001b[0;32m   5969\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mblocks) \u001b[38;5;241m!=\u001b[39m blocks_before:\n\u001b[0;32m   5970\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clear_item_cache()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:5978\u001b[0m, in \u001b[0;36mNDFrame._consolidate_inplace.<locals>.f\u001b[1;34m()\u001b[0m\n\u001b[0;32m   5977\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mf\u001b[39m():\n\u001b[1;32m-> 5978\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mconsolidate()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:686\u001b[0m, in \u001b[0;36mBaseBlockManager.consolidate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    684\u001b[0m bm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrefs, verify_integrity\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    685\u001b[0m bm\u001b[38;5;241m.\u001b[39m_is_consolidated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 686\u001b[0m bm\u001b[38;5;241m.\u001b[39m_consolidate_inplace()\n\u001b[0;32m    687\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m bm\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1873\u001b[0m, in \u001b[0;36mBlockManager._consolidate_inplace\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1871\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks \u001b[38;5;241m=\u001b[39m _consolidate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks)\n\u001b[0;32m   1872\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1873\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrefs \u001b[38;5;241m=\u001b[39m _consolidate_with_refs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrefs)\n\u001b[0;32m   1874\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_consolidated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_known_consolidated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:2350\u001b[0m, in \u001b[0;36m_consolidate_with_refs\u001b[1;34m(blocks, refs)\u001b[0m\n\u001b[0;32m   2348\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (_can_consolidate, dtype), group_blocks_refs \u001b[38;5;129;01min\u001b[39;00m grouper:\n\u001b[0;32m   2349\u001b[0m     group_blocks, group_refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(group_blocks_refs)))\n\u001b[1;32m-> 2350\u001b[0m     merged_blocks, consolidated \u001b[38;5;241m=\u001b[39m _merge_blocks(\n\u001b[0;32m   2351\u001b[0m         \u001b[38;5;28mlist\u001b[39m(group_blocks), dtype\u001b[38;5;241m=\u001b[39mdtype, can_consolidate\u001b[38;5;241m=\u001b[39m_can_consolidate\n\u001b[0;32m   2352\u001b[0m     )\n\u001b[0;32m   2353\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(merged_blocks, new_blocks)\n\u001b[0;32m   2354\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m consolidated:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:2388\u001b[0m, in \u001b[0;36m_merge_blocks\u001b[1;34m(blocks, dtype, can_consolidate)\u001b[0m\n\u001b[0;32m   2385\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m bvals2[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_concat_same_type(bvals2, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m   2387\u001b[0m argsort \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(new_mgr_locs)\n\u001b[1;32m-> 2388\u001b[0m new_values \u001b[38;5;241m=\u001b[39m new_values[argsort]\n\u001b[0;32m   2389\u001b[0m new_mgr_locs \u001b[38;5;241m=\u001b[39m new_mgr_locs[argsort]\n\u001b[0;32m   2391\u001b[0m bp \u001b[38;5;241m=\u001b[39m BlockPlacement(new_mgr_locs)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 662. MiB for an array with shape (18, 4824000) and data type int64"
     ]
    }
   ],
   "source": [
    "# Appliquer le one-hot encoding aux colonnes 'venue', 'action', et 'trade' pour X_test\n",
    "df1_test = one_hot_encode(X_test, 'venue', 8)\n",
    "df2_test = one_hot_encode(X_test, 'action', 8)\n",
    "df3_test = one_hot_encode(X_test, 'trade', 8)\n",
    "\n",
    "# Log Transform pour X_test\n",
    "X_test['flux'] = X_test['flux'] - X_test['flux'].min() + 1\n",
    "data_test = {\n",
    "    'log(bid_size+1)': np.log(X_test['bid_size'] + 1),\n",
    "    'log(ask_size+1)': np.log(X_test['ask_size'] + 1),\n",
    "    'log(flux)': np.log(X_test['flux'])\n",
    "}\n",
    "dfa_test = pd.DataFrame(data_test)\n",
    "X_selected_test = X_test[['bid', 'ask', 'price']]\n",
    "\n",
    "# Combiner les features pour X_test\n",
    "df_combined_test = pd.concat([df1_test, df2_test, df3_test, X_selected_test, dfa_test], axis=1)\n",
    "\n",
    "# Reshape the data to create sequences of (100, 30)\n",
    "# We need to ensure we have enough rows to create full sequences for X_test\n",
    "num_sequences_test = len(df_combined_test) // 100\n",
    "\n",
    "# Only take enough rows to form complete sequences\n",
    "X_combined_test = df_combined_test.iloc[:num_sequences_test * 100]\n",
    "\n",
    "# Reshape the data to the required shape\n",
    "X_reshaped_test = X_combined_test.values.reshape(num_sequences_test, 100, 30)\n",
    "\n",
    "# Convertir les labels en tenseurs pour Y_test\n",
    "Y_labels_test = pd.get_dummies(Y_test['eqt_code_cat']).values\n",
    "\n",
    "# Ensure Y_reshaped_test has the same number of sequences as X_reshaped_test\n",
    "Y_reshaped_test = Y_labels_test[:num_sequences_test]\n",
    "\n",
    "# Conversion en tenseurs pour X_test et Y_test\n",
    "X_tensor_test = tf.convert_to_tensor(X_reshaped_test, dtype=tf.float32)\n",
    "Y_tensor_test = tf.convert_to_tensor(Y_reshaped_test, dtype=tf.float32)\n",
    "\n",
    "# Évaluer le modèle sur l'ensemble de test\n",
    "loss, accuracy = model.evaluate(X_tensor_test, Y_tensor_test, verbose=0)\n",
    "print(f'Précision sur l\\'ensemble de test: {accuracy}')\n",
    "\n",
    "# Faire des prédictions et évaluer les performances\n",
    "y_pred = model.predict(X_tensor_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(Y_reshaped_test, axis=1)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print('Rapport de classification:')\n",
    "print(classification_report(y_true, y_pred_classes))\n",
    "print('Matrice de confusion:')\n",
    "print(confusion_matrix(y_true, y_pred_classes))\n",
    "\n",
    "# Visualiser l'historique d'entraînement (optionnel si vous avez l'historique)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assurez-vous d'avoir l'historique d'entraînement pour les graphiques\n",
    "history = model.fit(X_tensor, Y_tensor, batch_size=1000, epochs=3)\n",
    "\n",
    "# Précision\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Précision du modèle')\n",
    "plt.ylabel('Précision')\n",
    "plt.xlabel('Époque')\n",
    "plt.legend(['Entraînement', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Perte\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Perte du modèle')\n",
    "plt.ylabel('Perte')\n",
    "plt.xlabel('Époque')\n",
    "plt.legend(['Entraînement', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b83b81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appliquer le one-hot encoding aux colonnes 'venue', 'action', et 'trade' pour X_test\n",
    "df1_test = one_hot_encode(X_test, 'venue', 8)\n",
    "df2_test = one_hot_encode(X_test, 'action', 8)\n",
    "df3_test = one_hot_encode(X_test, 'trade', 8)\n",
    "\n",
    "# Log Transform pour X_test\n",
    "X_test['flux'] = X_test['flux'] - X_test['flux'].min() + 1\n",
    "data_test = {\n",
    "    'log(bid_size+1)': np.log(X_test['bid_size'] + 1),\n",
    "    'log(ask_size+1)': np.log(X_test['ask_size'] + 1),\n",
    "    'log(flux)': np.log(X_test['flux'])\n",
    "}\n",
    "dfa_test = pd.DataFrame(data_test)\n",
    "X_selected_test = X_test[['bid', 'ask', 'price']]\n",
    "\n",
    "# Combiner les features pour X_test\n",
    "df_combined_test = pd.concat([df1_test, df2_test, df3_test, X_selected_test, dfa_test], axis=1)\n",
    "\n",
    "# Reshape the data to create sequences of (100, 30)\n",
    "# We need to ensure we have enough rows to create full sequences for X_test\n",
    "num_sequences_test = len(df_combined_test) // 100\n",
    "X_reshaped_test = df_combined_test.iloc[:num_sequences_test * 100].values.reshape(num_sequences_test, 100, 30)\n",
    "\n",
    "# Convertir les labels en tenseurs pour Y_test\n",
    "Y_labels_test = pd.get_dummies(Y_test['eqt_code_cat']).values\n",
    "Y_reshaped_test = Y_labels_test[:num_sequences_test]\n",
    "\n",
    "# Conversion en tenseurs pour X_test et Y_test\n",
    "X_tensor_test = tf.convert_to_tensor(X_reshaped_test, dtype=tf.float32)\n",
    "Y_tensor_test = tf.convert_to_tensor(Y_reshaped_test, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6426f36",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Data cardinality is ambiguous:\n  x sizes: 4824000\n  y sizes: 48240\nMake sure all arrays contain the same number of samples.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 6. Évaluer le modèle sur l'ensemble de test\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m loss, accuracy \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(X_test, Y_test, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrécision sur l\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mensemble de test: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\data_adapter.py:1960\u001b[0m, in \u001b[0;36m_check_data_cardinality\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m   1953\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m sizes: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   1954\u001b[0m         label,\n\u001b[0;32m   1955\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[0;32m   1956\u001b[0m             \u001b[38;5;28mstr\u001b[39m(i\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(single_data)\n\u001b[0;32m   1957\u001b[0m         ),\n\u001b[0;32m   1958\u001b[0m     )\n\u001b[0;32m   1959\u001b[0m msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMake sure all arrays contain the same number of samples.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1960\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n",
      "\u001b[1;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 4824000\n  y sizes: 48240\nMake sure all arrays contain the same number of samples."
     ]
    }
   ],
   "source": [
    "# 6. Évaluer le modèle sur l'ensemble de test\n",
    "loss, accuracy = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print(f'Précision sur l\\'ensemble de test: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da64e11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faire des prédictions et évaluer les performances\n",
    "y_pred = model.predict(X_tensor_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(Y_reshaped_test, axis=1)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print('Rapport de classification:')\n",
    "print(classification_report(y_true, y_pred_classes))\n",
    "print('Matrice de confusion:')\n",
    "print(confusion_matrix(y_true, y_pred_classes))\n",
    "\n",
    "# Visualiser l'historique d'entraînement (optionnel si vous avez l'historique)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assurez-vous d'avoir l'historique d'entraînement pour les graphiques\n",
    "history = model.fit(X_tensor, Y_tensor, batch_size=1000, epochs=3)\n",
    "\n",
    "# Précision\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Précision du modèle')\n",
    "plt.ylabel('Précision')\n",
    "plt.xlabel('Époque')\n",
    "plt.legend(['Entraînement', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Perte\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Perte du modèle')\n",
    "plt.ylabel('Perte')\n",
    "plt.xlabel('Époque')\n",
    "plt.legend(['Entraînement', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672fecae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b616803b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990b8eeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
